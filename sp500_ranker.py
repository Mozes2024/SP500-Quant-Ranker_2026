# ============================================================
# S&P 500 ADVANCED RANKING SYSTEM v5.2 â€“ GitHub Edition (FULL)
# Headless + Actions Cache + Fixed yf_data + Robust error handling
# ============================================================

import subprocess, sys, os, pickle, time, shutil
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed

subprocess.check_call([sys.executable, "-m", "pip", "install",
    "yfinance", "pandas", "numpy", "openpyxl==3.1.2", "requests",
    "beautifulsoup4", "matplotlib", "seaborn", "tqdm", "scipy", "-q"])

import yfinance as yf
import pandas as pd
import numpy as np
import requests
import warnings
from bs4 import BeautifulSoup
from tqdm import tqdm
from scipy.stats import percentileofscore
import matplotlib.pyplot as plt
import seaborn as sns
from openpyxl.styles import PatternFill, Font, Alignment, Border, Side
from openpyxl.utils import get_column_letter
from openpyxl.formatting.rule import ColorScaleRule

warnings.filterwarnings("ignore")
pd.set_option("display.max_columns", None)
pd.set_option("display.float_format", "{:.2f}".format)

# ====================== CONFIG ======================
CFG = {
    "weights": {
        "valuation": 0.19, "profitability": 0.16, "growth": 0.13,
        "earnings_quality": 0.08, "fcf_quality": 0.13,
        "financial_health": 0.09, "momentum": 0.09,
        "analyst": 0.11, "piotroski": 0.02,
    },
    "min_coverage": 0.45,
    "min_market_cap": 5_000_000_000,
    "min_avg_volume": 500_000,
    "cache_hours": 24,
    "sleep_tr": 0.35,
    "batch_size_tr": 10,
    "max_workers_yf": 20,
    "output_file": "artifacts/sp500_ranking_v5.2.xlsx",
}
assert abs(sum(CFG["weights"].values()) - 1.0) < 1e-6

CACHE_FILE = "sp500_cache_v5.pkl"
os.makedirs("artifacts", exist_ok=True)

# ====================== TIPRANKS ======================
TR_URL = "https://mobile.tipranks.com/api/stocks/stockAnalysisOverview"
TR_HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36",
    "Accept": "application/json, text/plain, */*",
    "Accept-Language": "en-US,en;q=0.9",
    "Accept-Encoding": "gzip, deflate, br",
    "Referer": "https://www.tipranks.com/",
    "Origin": "https://www.tipranks.com",
    "Connection": "keep-alive",
    "Sec-Fetch-Dest": "empty",
    "Sec-Fetch-Mode": "cors",
    "Sec-Fetch-Site": "same-site",
}

_CONSENSUS = {"StrongBuy": 5, "Buy": 4, "Moderate Buy": 3.5, "Hold": 3, "Moderate Sell": 2, "Sell": 1, "StrongSell": 0}
_TREND = {"Increased": 1, "Unchanged": 0, "Decreased": -1, "BoughtShares": 1, "SoldShares": -1}
_SENTIMENT = {"VeryBullish": 5, "Bullish": 4, "Neutral": 3, "Bearish": 2, "VeryBearish": 1, "VeryPositive": 5, "Positive": 4, "Negative": 2, "VeryNegative": 1}
_SMA = {"Positive": 1, "Neutral": 0, "Negative": -1}

def _parse_tipranks(item: dict) -> dict:
    return { ... }  # â† ××•×ª×• ×¤×•× ×§×¦×™×” ×›××• ×‘×’×¨×¡×” v5.1 ×©×œ×š (×”×¢×ª×§ ××•×ª×”)

def fetch_tipranks(tickers: list) -> pd.DataFrame:
    # â† ××•×ª×• ×§×•×“ ×›××• ×‘×’×¨×¡×” v5.1 ×©×œ×š

# ====================== S&P 500 TICKERS ======================
# â† ×”×¢×ª×§ ××ª get_sp500_tickers() ×”××œ××” ××’×¨×¡×” v5.1 ×©×œ×š

# ====================== YAHOO + MOMENTUM ======================
FUNDAMENTAL_FIELDS = [ ... ]  # â† ×”×¢×ª×§ ××ª ×”×¨×©×™××” ×”××œ××”

def _get_one(ticker: str) -> tuple:
    try:
        info = yf.Ticker(ticker).info
        return ticker, {k: info.get(k) for k in FUNDAMENTAL_FIELDS}
    except:
        return ticker, {}

def fetch_yf_parallel(tickers: list) -> dict:
    results = {}
    with ThreadPoolExecutor(max_workers=CFG["max_workers_yf"]) as executor:
        futures = {executor.submit(_get_one, t): t for t in tickers}
        for future in tqdm(as_completed(futures), total=len(tickers), desc="Yahoo Finance (parallel)"):
            t, info = future.result()
            results[t] = info
    return results   # â† ×ª××™×“ ××—×–×™×¨ dict (×’× ×× ×¨×™×§)

def fetch_price_multi(tickers: list) -> pd.DataFrame:
    # â† ××•×ª×• ×§×•×“

def add_price_momentum(df: pd.DataFrame, tickers: list) -> pd.DataFrame:
    # â† ××•×ª×• ×§×•×“

# ====================== COMPUTED METRICS ======================
# â† ×”×¢×ª×§ ×›××Ÿ ××ª ×›×œ ×”×¤×•× ×§×¦×™×•×ª compute_... , _safe, sector_percentile, build_pillar_scores, compute_composite,
# compute_valuation_score, build_sector_thresholds, compute_coverage, add_sector_context â€“ ×‘×“×™×•×§ ×›××• ×‘×’×¨×¡×” v5.1 ×©×œ×š

# ====================== CACHING ======================
_SECTOR_THRESHOLDS = {}

def load_cache():
    global _SECTOR_THRESHOLDS
    if not os.path.exists(CACHE_FILE):
        return None
    try:
        with open(CACHE_FILE, "rb") as f:
            payload = pickle.load(f)
        if len(payload) == 3:
            data, saved_thresholds, ts = payload
            _SECTOR_THRESHOLDS = saved_thresholds
        else:
            data, ts = payload
            _SECTOR_THRESHOLDS = build_sector_thresholds(data)
        if (datetime.now() - ts) < timedelta(hours=CFG["cache_hours"]):
            print(f"âœ… Cache loaded")
            return data
    except:
        pass
    return None

def save_cache(df):
    try:
        with open(CACHE_FILE, "wb") as f:
            pickle.dump((df, _SECTOR_THRESHOLDS, datetime.now()), f)
        print("ğŸ’¾ Cache saved")
    except:
        pass

# ====================== EXCEL + PLOTS ======================
# â† ×”×¢×ª×§ ×›××Ÿ ××ª style_and_export, _format_sheet, plot_all, _plot_radar, _print_summary â€“ ×‘×“×™×•×§ ×›××• ×‘×’×¨×¡×” v5.1

# ====================== MAIN PIPELINE (××ª×•×§×Ÿ) ======================
def run_pipeline(use_cache: bool = True):
    global _SECTOR_THRESHOLDS
    print("=" * 70)
    print(f" S&P 500 ADVANCED RANKING v5.2 â€“ {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    print("=" * 70)

    cached = load_cache() if use_cache else None
    if cached is not None:
        df = cached.copy()
        print("âœ… Using cache")
    else:
        universe = get_sp500_tickers()
        tickers = universe["ticker"].tolist()
        print(f"ğŸ“¥ Fetching Yahoo data ({len(tickers)} tickers)...")
        yf_data = fetch_yf_parallel(tickers)
        if yf_data is None:          # â† FIX ×›××Ÿ
            yf_data = {}
        fund_df = pd.DataFrame.from_dict(yf_data, orient="index").reset_index()
        fund_df.rename(columns={"index": "ticker"}, inplace=True)
        df = universe.merge(fund_df, on="ticker", how="left")
        tr_df = fetch_tipranks(tickers)
        if not tr_df.empty:
            df = df.merge(tr_df, on="ticker", how="left")
        # â† ×”××©×š ×›×œ ×”-compute, liquidity, coverage, thresholds, pillars, composite, valuation, rank, sector context
        # (×”×¢×ª×§ ××ª ×”×‘×œ×•×§ ×”×–×” ××’×¨×¡×” v5.1 ×©×œ×š â€“ ×”×•× ×–×”×”)

        _SECTOR_THRESHOLDS = build_sector_thresholds(df)
        save_cache(df)

    _print_summary(df)
    print("ğŸ¨ Generating charts...")
    plot_all(df)
    print("ğŸ’¾ Exporting Excel...")
    style_and_export(df, CFG["output_file"])

    for f in ["top30_composite.png", "sector_scores.png", "valuation_vs_quality.png",
              "smartscore_dist.png", "momentum_decomp.png", "top5_radar.png"]:
        if os.path.exists(f):
            shutil.copy(f, f"artifacts/{f}")

    print("âœ… DONE! Artifacts ready.")
    return df

# ====================== RUN ======================
if __name__ == "__main__":
    run_pipeline(use_cache=True)
